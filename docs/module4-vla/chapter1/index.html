<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module4-vla/chapter1" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Voice-to-Action with Whisper: Capturing and Interpreting Commands | Physical AI &amp; Humanoid Robotics Textbook</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://Amnariazrit.github.io/physical-ai-humanoid-robotics-textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://Amnariazrit.github.io/physical-ai-humanoid-robotics-textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://Amnariazrit.github.io/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter1"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Voice-to-Action with Whisper: Capturing and Interpreting Commands | Physical AI &amp; Humanoid Robotics Textbook"><meta data-rh="true" name="description" content="Natural Language Processing (NLP) plays a pivotal role in enabling more intuitive and human-like interactions with robots. For humanoid robots, the ability to understand and act upon spoken commands is a significant step towards seamless collaboration. This chapter explores how to integrate voice commands into a robotic system using advanced speech-to-text models, specifically focusing on OpenAI&#x27;s Whisper, and translating these into actionable instructions for a ROS 2-controlled humanoid."><meta data-rh="true" property="og:description" content="Natural Language Processing (NLP) plays a pivotal role in enabling more intuitive and human-like interactions with robots. For humanoid robots, the ability to understand and act upon spoken commands is a significant step towards seamless collaboration. This chapter explores how to integrate voice commands into a robotic system using advanced speech-to-text models, specifically focusing on OpenAI&#x27;s Whisper, and translating these into actionable instructions for a ROS 2-controlled humanoid."><link data-rh="true" rel="icon" href="/physical-ai-humanoid-robotics-textbook/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://Amnariazrit.github.io/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter1"><link data-rh="true" rel="alternate" href="https://Amnariazrit.github.io/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter1" hreflang="en"><link data-rh="true" rel="alternate" href="https://Amnariazrit.github.io/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter1" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Module 4: Vision-Language-Action (VLA)","item":"https://Amnariazrit.github.io/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter1"}]}</script><link rel="alternate" type="application/rss+xml" href="/physical-ai-humanoid-robotics-textbook/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics Textbook RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/physical-ai-humanoid-robotics-textbook/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Textbook Atom Feed"><link rel="stylesheet" href="/physical-ai-humanoid-robotics-textbook/assets/css/styles.fc6aef72.css">
<script src="/physical-ai-humanoid-robotics-textbook/assets/js/runtime~main.d7fd4308.js" defer="defer"></script>
<script src="/physical-ai-humanoid-robotics-textbook/assets/js/main.381a09d3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/physical-ai-humanoid-robotics-textbook/"><div class="navbar__logo"><img src="/physical-ai-humanoid-robotics-textbook/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/physical-ai-humanoid-robotics-textbook/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics Textbook</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/physical-ai-humanoid-robotics-textbook/docs/module1-ros2/chapter1">Textbook</a><a class="navbar__item navbar__link" href="/physical-ai-humanoid-robotics-textbook/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/Amnariazrit/physical-ai-humanoid-robotics-textbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/physical-ai-humanoid-robotics-textbook/docs/module1-ros2/chapter1"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a><button aria-label="Expand sidebar category &#x27;Module 1: The Robotic Nervous System (ROS 2)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/physical-ai-humanoid-robotics-textbook/docs/module2-gazebo/chapter1"><span title="Module 2: The Digital Twin (Gazebo &amp; Unity)" class="categoryLinkLabel_W154">Module 2: The Digital Twin (Gazebo &amp; Unity)</span></a><button aria-label="Expand sidebar category &#x27;Module 2: The Digital Twin (Gazebo &amp; Unity)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/physical-ai-humanoid-robotics-textbook/docs/module3-isaac/chapter1"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaac)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaac)</span></a><button aria-label="Expand sidebar category &#x27;Module 3: The AI-Robot Brain (NVIDIA Isaac)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" aria-current="page" href="/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter1"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a><button aria-label="Collapse sidebar category &#x27;Module 4: Vision-Language-Action (VLA)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter1"><span title="Voice-to-Action with Whisper: Capturing and Interpreting Commands" class="linkLabel_WmDU">Voice-to-Action with Whisper: Capturing and Interpreting Commands</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter2"><span title="Cognitive Planning: LLM Planning of Sequences" class="linkLabel_WmDU">Cognitive Planning: LLM Planning of Sequences</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter3"><span title="ROS 2 Action Sequencing: Executing Planned Actions" class="linkLabel_WmDU">ROS 2 Action Sequencing: Executing Planned Actions</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter4"><span title="Multi-modal Interaction: Speech, Gesture, Vision Integration" class="linkLabel_WmDU">Multi-modal Interaction: Speech, Gesture, Vision Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter5"><span title="Capstone Integration: Autonomous Humanoid Demonstration" class="linkLabel_WmDU">Capstone Integration: Autonomous Humanoid Demonstration</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/physical-ai-humanoid-robotics-textbook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Module 4: Vision-Language-Action (VLA)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Voice-to-Action with Whisper: Capturing and Interpreting Commands</h1></header>
<p>Natural Language Processing (NLP) plays a pivotal role in enabling more intuitive and human-like interactions with robots. For humanoid robots, the ability to understand and act upon spoken commands is a significant step towards seamless collaboration. This chapter explores how to integrate voice commands into a robotic system using advanced speech-to-text models, specifically focusing on OpenAI&#x27;s Whisper, and translating these into actionable instructions for a ROS 2-controlled humanoid.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-role-of-voice-commands-in-humanoid-robotics">The Role of Voice Commands in Humanoid Robotics<a href="#the-role-of-voice-commands-in-humanoid-robotics" class="hash-link" aria-label="Direct link to The Role of Voice Commands in Humanoid Robotics" title="Direct link to The Role of Voice Commands in Humanoid Robotics" translate="no">​</a></h2>
<p>Voice commands offer several advantages for controlling humanoid robots:</p>
<ul>
<li class=""><strong>Natural Interaction</strong>: Humans naturally communicate through speech, making voice commands intuitive and accessible.</li>
<li class=""><strong>Hands-Free Operation</strong>: Allows operators to control robots without physical contact, useful in complex tasks or when hands are occupied.</li>
<li class=""><strong>Accessibility</strong>: Provides an alternative control method for individuals with limited mobility.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="openai-whisper-speech-to-text-model">OpenAI Whisper: Speech-to-Text Model<a href="#openai-whisper-speech-to-text-model" class="hash-link" aria-label="Direct link to OpenAI Whisper: Speech-to-Text Model" title="Direct link to OpenAI Whisper: Speech-to-Text Model" translate="no">​</a></h2>
<p>OpenAI Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is capable of transcribing speech into text, translating multiple languages into English, and even identifying the language being spoken. Its robust performance across various accents and noisy environments makes it an excellent choice for robotics applications.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-features-of-whisper">Key Features of Whisper:<a href="#key-features-of-whisper" class="hash-link" aria-label="Direct link to Key Features of Whisper:" title="Direct link to Key Features of Whisper:" translate="no">​</a></h3>
<ul>
<li class=""><strong>High Accuracy</strong>: State-of-the-art performance in speech recognition.</li>
<li class=""><strong>Multilingual Support</strong>: Can transcribe and translate speech from many languages.</li>
<li class=""><strong>Robustness</strong>: Handles background noise, varying accents, and different speaking styles well.</li>
<li class=""><strong>Open Source</strong>: The models and code are publicly available, allowing for local deployment and customization.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="integrating-whisper-with-a-ros-2-system">Integrating Whisper with a ROS 2 System<a href="#integrating-whisper-with-a-ros-2-system" class="hash-link" aria-label="Direct link to Integrating Whisper with a ROS 2 System" title="Direct link to Integrating Whisper with a ROS 2 System" translate="no">​</a></h2>
<p>The general workflow for voice-to-action integration with Whisper in a ROS 2 system involves:</p>
<ol>
<li class=""><strong>Audio Capture</strong>: Capturing audio input from a microphone.</li>
<li class=""><strong>Speech-to-Text Transcription</strong>: Processing the audio with Whisper to convert it into text.</li>
<li class=""><strong>Natural Language Understanding (NLU)</strong>: Interpreting the transcribed text to extract the user&#x27;s intent and any relevant parameters (e.g., &quot;move forward 2 meters,&quot; &quot;pick up the red block&quot;). This step often involves a separate language model or a rule-based system.</li>
<li class=""><strong>Action Mapping</strong>: Translating the understood intent into specific ROS 2 commands (e.g., publishing a velocity command, sending an action goal).</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="conceptual-ros-2-node-for-whisper-integration">Conceptual ROS 2 Node for Whisper Integration:<a href="#conceptual-ros-2-node-for-whisper-integration" class="hash-link" aria-label="Direct link to Conceptual ROS 2 Node for Whisper Integration:" title="Direct link to Conceptual ROS 2 Node for Whisper Integration:" translate="no">​</a></h3>
<p>A ROS 2 node could be developed in Python (<code>rclpy</code>) that encapsulates this workflow:</p>
<ol>
<li class=""><strong>Audio Input Node</strong>: A node that continuously captures audio from a microphone and publishes raw audio data (e.g., as <code>audio_common_msgs/AudioData</code> or a custom message type) to a ROS 2 topic.</li>
<li class=""><strong>Whisper Transcription Node</strong>: A node that subscribes to the audio data topic.
<ul>
<li class="">When a &quot;speech detected&quot; event occurs (or periodically), it passes the audio buffer to the Whisper model.</li>
<li class="">It publishes the transcribed text (e.g., <code>std_msgs/String</code>) to a <code>robot_command_text</code> topic.</li>
</ul>
</li>
<li class=""><strong>Command Interpreter Node</strong>: A node that subscribes to the <code>robot_command_text</code> topic.
<ul>
<li class="">It uses NLU techniques (e.g., simple keyword spotting, rule-based parsing, or a small language model) to extract the robot&#x27;s intended action and parameters.</li>
<li class="">It then translates this intent into appropriate ROS 2 API calls (e.g., publish to a velocity command topic, send an action goal to a manipulation server).</li>
</ul>
</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-voice-control-for-simple-humanoid-movement">Example: Voice Control for Simple Humanoid Movement<a href="#example-voice-control-for-simple-humanoid-movement" class="hash-link" aria-label="Direct link to Example: Voice Control for Simple Humanoid Movement" title="Direct link to Example: Voice Control for Simple Humanoid Movement" translate="no">​</a></h2>
<p>Let&#x27;s conceptualize a simple voice control system for our generic humanoid.</p>
<p><strong>Desired Commands</strong>:</p>
<ul>
<li class="">&quot;Robot, move forward.&quot;</li>
<li class="">&quot;Robot, turn left.&quot;</li>
<li class="">&quot;Robot, stop.&quot;</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="implementation-steps-conceptual">Implementation Steps (Conceptual):<a href="#implementation-steps-conceptual" class="hash-link" aria-label="Direct link to Implementation Steps (Conceptual):" title="Direct link to Implementation Steps (Conceptual):" translate="no">​</a></h3>
<ol>
<li class=""><strong>Microphone Setup</strong>: Ensure a microphone is connected to your robot&#x27;s computer (or your development machine) and is accessible by the ROS 2 system.</li>
<li class=""><strong>Python Script for Audio Capture and Whisper</strong>: Write a Python script using <code>pyaudio</code> or similar libraries to capture audio. Integrate the Whisper model (e.g., <code>openai-whisper</code> Python package) to transcribe the audio.</li>
<li class=""><strong>ROS 2 Node for Command Interpretation</strong>:
<ul>
<li class="">Create a ROS 2 Python node (e.g., <code>voice_command_interpreter</code>).</li>
<li class="">This node subscribes to a <code>/whisper_text</code> topic (where Whisper publishes its output).</li>
<li class="">Implement basic NLU logic:
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">text_callback</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> msg</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    command_text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> msg</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lower</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;move forward&quot;</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> command_text</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Moving forward!&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Publish ROS 2 velocity command or action goal</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">elif</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;turn left&quot;</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> command_text</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Turning left!&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Publish ROS 2 turn command</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">elif</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;stop&quot;</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> command_text</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Stopping!&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Publish ROS 2 stop command</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">else</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Unknown command: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">command_text</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
</li>
<li class="">The node would then publish appropriate control messages (e.g., <code>geometry_msgs/Twist</code> for velocity) to the humanoid&#x27;s base controller.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="challenges">Challenges:<a href="#challenges" class="hash-link" aria-label="Direct link to Challenges:" title="Direct link to Challenges:" translate="no">​</a></h3>
<ul>
<li class=""><strong>Latency</strong>: Real-time voice interaction requires low latency in speech-to-text and command processing.</li>
<li class=""><strong>Robustness</strong>: Handling variations in speech, accents, and noisy environments.</li>
<li class=""><strong>Command Ambiguity</strong>: Distinguishing between similar-sounding commands or understanding context.</li>
<li class=""><strong>Resource Usage</strong>: Running large Whisper models locally can be computationally intensive, especially on embedded robotic platforms. Cloud-based Whisper APIs or smaller, optimized models might be necessary.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" translate="no">​</a></h2>
<p>Integrating voice commands via models like OpenAI Whisper offers a powerful and natural interface for controlling humanoid robots. By combining accurate speech-to-text transcription with robust natural language understanding and ROS 2 action mapping, we can enable robots to respond intelligently to human speech. The next chapter will delve into cognitive planning, where larger language models can be used to plan sequences of actions based on more complex natural language instructions.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module4-vla/chapter1.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/physical-ai-humanoid-robotics-textbook/docs/module3-isaac/chapter5"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Sim-to-Real Transfer: Deploying Models to Real Robots</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/physical-ai-humanoid-robotics-textbook/docs/module4-vla/chapter1"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Voice-to-Action with Whisper: Capturing and Interpreting Commands</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-role-of-voice-commands-in-humanoid-robotics" class="table-of-contents__link toc-highlight">The Role of Voice Commands in Humanoid Robotics</a></li><li><a href="#openai-whisper-speech-to-text-model" class="table-of-contents__link toc-highlight">OpenAI Whisper: Speech-to-Text Model</a><ul><li><a href="#key-features-of-whisper" class="table-of-contents__link toc-highlight">Key Features of Whisper:</a></li></ul></li><li><a href="#integrating-whisper-with-a-ros-2-system" class="table-of-contents__link toc-highlight">Integrating Whisper with a ROS 2 System</a><ul><li><a href="#conceptual-ros-2-node-for-whisper-integration" class="table-of-contents__link toc-highlight">Conceptual ROS 2 Node for Whisper Integration:</a></li></ul></li><li><a href="#example-voice-control-for-simple-humanoid-movement" class="table-of-contents__link toc-highlight">Example: Voice Control for Simple Humanoid Movement</a><ul><li><a href="#implementation-steps-conceptual" class="table-of-contents__link toc-highlight">Implementation Steps (Conceptual):</a></li><li><a href="#challenges" class="table-of-contents__link toc-highlight">Challenges:</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-humanoid-robotics-textbook/docs/module1-ros2/chapter1">Textbook</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-humanoid-robotics-textbook/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/Amnariazrit/physical-ai-humanoid-robotics-textbook" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Textbook. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>